# Ultimate Global
The goal of Vision for Robotics is **make robot understand a scene by cameras and sensors and give people service**

##### What Service?
- Pick up and Delivery
   - SLAM
   - Object Detection & Recognition
   - Object Pose estimation
   - Grasp

SLAM : *Not* my interest
Object Detection & Recognition for known objects : V4R
Object Pose estimation for known objects : V4R
Object Detection & recognition & pose estimation for Grasping with Unknown? : Not performed in V4R, Who's doing this?

Grasping unknown and Learning and it can pick up and delivery well?

```{mermaid}
graph LR
A["1. Unknown objects in Scene"] --> B["2. Grasp Unknown"]
B --> C[3. Known Object Generation]
C --> D[4. Grasp Known]
```
Segmentation of unknown object but can be grasp object in Scene

나의 그림
Training Step
1. 책상에 물건이 있다. 처음엔 모든 물건이 뭔지 모른다. Segmentation도 제한적이다.
2. 로봇이 다가간다.
3. Pick up할 물체를 선택한다
   - 완전 모르는 물체를 선택한다
   - 완전 모르는 물체지만 뭔가 잡을 것 같은 느낌적인 느낌의 물건을 선택한다.
    (Transfer Learning)
   - 대충 아는 물체를 선택한다. (추가 학습 & Grasp 학습)
   - 완전 아는 물체를 선택한다 (Grasp policy 강화)
4. Grasp을 한다.
5. 모델을 돌려가며 학습을 한다.
6. 학습한 물체를 다른데 놓는다
7. 3-6을 반복한다.
8. 몇일 또는 몇번을. 로봇은 이제 책상에 모든 물체를 배웠고 잡을 줄 안다.
9. 각각 모델링 된 물체는 Human Robot interaction을 이용하여 Labeling한다.

Deployment Step
1. 책상에 아무렇게나 물건을 널부러 트려놓는다.
     - 가정1) 모든 물건을 사전 학습 되어있다.
     - 가정2) 사전 학습 된 물건과 아닌 물건이 섞여 있다.
     - 별상관이 없을 수 있다.
2. 특정 물건을 가져오라고 시킨다.
3. 로봇이 Grasp까지 잘 해서 가져다 준다.

Challenge
- 잘 모르는 물체지만 Grasp을 성공한 물체 중 비슷한 물체를 이용하여 쉽게 잡는 것.
- Grasp그 자체
- Unknown object의 segmentation : V4R
- 모델 돌려가며 학습 : Extension of V4R (with Mobile robot -> grasp 보다 고전)
